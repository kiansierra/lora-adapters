{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (4.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: filelock in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: lora_adapters in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (0.1.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: packaging in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pandas in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: aiohttp in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: multiprocess in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: evaluate in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (1.24.2)\n",
      "Requirement already satisfied: dill in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: packaging in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (2.11.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: pandas in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: multiprocess in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (2023.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (2.28.2)\n",
      "Requirement already satisfied: responses<0.19 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (0.13.3)\n",
      "Requirement already satisfied: xxhash in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: filelock in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.10.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install lora_adapters\n",
    "!pip install datasets\n",
    "!pip install evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding, default_data_collator\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from lora_adapters import LoraMergedLinear, LoraLinear, LoraEmbedding, apply_adapter, mark_only_lora_as_trainable, lora_state_dict, undo_lora\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-3b\", padding_side=\"left\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"databricks/dolly-v2-3b\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): LoraEmbedding(\n",
       "      50280, 2560, rank=16\n",
       "      (lora_dropout): Identity()\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): LoraMergedLinear(\n",
       "            in_features=2560, out_features=7680, bias=True, rank=16, enable_lora=[True, False, True]\n",
       "            (lora_dropout): Identity()\n",
       "          )\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (6-9): 4 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=2560, out_features=7680, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (10-31): 22 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): LoraMergedLinear(\n",
       "            in_features=2560, out_features=7680, bias=True, rank=16, enable_lora=[True, False, True]\n",
       "            (lora_dropout): Identity()\n",
       "          )\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=2560, out_features=50280, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_LORA = True\n",
    "if USE_LORA:\n",
    "    model = apply_adapter(model, LoraEmbedding, rank=16, regex_pattern=\".*embed_in\")\n",
    "    model = apply_adapter(model, LoraMergedLinear, rank=16, regex_pattern=\".*[0-5].*query_key_value\")\n",
    "    model = mark_only_lora_as_trainable(model, bias='lora_only')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/kian/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-6e0f9ea7eaa0ee08/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2598a93e2f4107bc98fc1486389153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'context', 'response', 'category'],\n",
       "    num_rows: 15011\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\")\n",
    "train_dataset = dataset['train']\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    outputs = tokenizer(batch['instruction'], padding='max_length', truncation=True, max_length=128)\n",
    "    outputs['label_ids'] = tokenizer(batch['instruction'], padding='max_length', truncation=True, max_length=128).input_ids\n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kian/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-6e0f9ea7eaa0ee08/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-07875e2139150a01.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize)\n",
    "train_dataset = train_dataset.select_columns(['input_ids', 'attention_mask', 'label_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([512, 128])\n",
      "attention_mask torch.Size([512, 128])\n",
      "labels torch.Size([512, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer, padding=True,  max_length=2048)\n",
    "batch = collate_fn(train_dataset[:512])\n",
    "for k,v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\", per_device_train_batch_size=48, per_device_eval_batch_size=64, report_to=\"none\", bf16=True)\n",
    "optimizer = AdamW((param for param in model.parameters() if param.requires_grad), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers=(optimizer, None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0282243adf459caa479322d48a676e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.9478, 'learning_rate': 0.00046751863684771036, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kian/anaconda3/envs/torch-2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1893.7981, 'train_samples_per_second': 23.779, 'train_steps_per_second': 0.496, 'train_loss': 6.7459608896598775, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=939, training_loss=6.7459608896598775, metrics={'train_runtime': 1893.7981, 'train_samples_per_second': 23.779, 'train_steps_per_second': 0.496, 'train_loss': 6.7459608896598775, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"COLAB_BACKEND_VERSION\", None):\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
